{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"./\"\n",
    "all_files = glob.glob(os.path.join(path, \"./Datasets/api_comic_list*.csv\"))\n",
    "df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "df_merged.to_csv( \"./Datasets/merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_host = \"bolt://localhost:7687\"\n",
    "password = \"1234qwer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_characters = pd.read_csv(\"./Datasets/api_character_list.csv\")\n",
    "scraping_characters = pd.read_csv(\n",
    "    \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "api_comics = pd.read_csv(\"./Datasets/merged.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraping_characters.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_characters.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add characters nodes with variant from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comic_node(tx, comic_title,comic_id, comic_description):\n",
    "  comic_description = str(comic_description).replace(\n",
    "      \"'\", \" \").replace('\"', \"\").replace(\"-\", \" \").strip()\n",
    "  create_comic_node_query = 'MERGE (c:comic {title:\"%s\", comic_id: %s, comic_description: \"%s\"})' % (\n",
    "      comic_title, comic_id, comic_description)\n",
    "  node_creation_result = tx.run(create_comic_node_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\",password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiunta personaggi ottenuti dalla web api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_character_node(tx, name, character_id, character_description):\n",
    "  processed_name = name.replace('\"', \" \").replace('\"',\" \")\n",
    "  nome_senza_parentesi = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", processed_name.strip())\n",
    "  query_string = 'MERGE (c:character{name: \"%s\"})' %(nome_senza_parentesi.replace(\"'\", \" \").lower().strip())\n",
    "  tx.run(query_string)\n",
    "  tx.run(\n",
    "      \"MERGE (n:character_variant {name: '%s', character_id: %s, character_description: '%s'})\" %(name.replace(\"'\", ' ').replace('\"', \" \").replace(\"-\", \" \"), character_id, str(character_description).replace(\"'\", ' ').replace('\"', \" \").replace(\"-\", \" \")))\n",
    "  query_variant = 'MATCH (a:character{name:\"%s\"}),(b:character_variant {name: \"%s\", character_id: %s, character_description: \"%s\"}) MERGE (b)-[r:variante_di]->(a)' % (\n",
    "      nome_senza_parentesi.replace(\"'\", \" \").lower().strip(), name.replace(\"'\", ' ').replace('\"', \" \").replace(\"-\", \" \").strip(), character_id, str(character_description).replace(\"'\", ' ').replace('\"', \" \").replace(\"-\", \" \").strip(),)\n",
    "  tx.run(query_variant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1559/1559 [01:02<00:00, 24.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, row in tqdm(api_characters.iterrows(), total=api_characters.shape[0]):\n",
    "    with driver.session() as session:\n",
    "        try:\n",
    "            session.write_transaction(\n",
    "                add_character_node, row['name'], row[\"id\"], row[\"description\"])\n",
    "        except Exception as e:\n",
    "            print(e\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserimento fumetti ottenuti dalla web api e collegamento con gli eventuali personaggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_comic_node_and_link(tx, comic_title, comic_id, character_id, comic_description,  format, page_count, isbn, upc, diamond_code,ean, issn):\n",
    "  comic_description = str(comic_description).replace(\"'\", \" \").replace('\"',\"\").replace(\"-\",\" \").strip()\n",
    "  create_comic_node_query = 'MERGE (c:comic {title:\"%s\", comic_id: %s, comic_description: \"%s\", format : \"%s\", page_count : %s, isbn: \"%s\", upc: \"%s\", diamond_code: \"%s\",ean:\"%s\", issn: \"%s\" })' % (\n",
    "      comic_title, comic_id, comic_description, format, page_count, isbn, upc, diamond_code,ean, issn)\n",
    "  create_link_query = \"MATCH (a:character_variant),(b:comic) WHERE a.character_id = %s AND b.comic_id = %s MERGE (a)-[r:Presente]->(b)\" % (\n",
    "      character_id, comic_id)\n",
    "  # print(create_link_query)\n",
    "  node_creation_result = tx.run(create_comic_node_query)\n",
    "  link_creation_result = tx.run(create_link_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_comic(tx, comic_id, format, page_count, isbn, upc, diamond_code,ean, issn):\n",
    "  tx.run(\"MATCH (c:comic) WHERE c.comic_id = %s SET c.format = '%s', c.page_count = %s, c.isbn= '%s', c.upc= '%s', c.diamond_code= '%s', c.ean='%s', c.issn= '%s'\" %\n",
    "         (comic_id, format, page_count, isbn, upc, diamond_code,ean, issn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50645/50645 [1:11:46<00:00, 11.76it/s]  \n"
     ]
    }
   ],
   "source": [
    "with driver.session() as session:\n",
    "  for idx, row in tqdm(api_comics.iterrows(), total=api_comics.shape[0]):\n",
    "    try:\n",
    "        \n",
    "        session.write_transaction(\n",
    "            update_comic,  row[\"id\"],  str(row[\"format\"]), str(row[\"pageCount\"]), str(row[\"isbn\"]), str(row[\"upc\"]), str(row[\"diamondCode\"]), str(row[\"ean\"]), str(row[\"issn\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(api_comics.iterrows(), total=api_comics.shape[0]):\n",
    "    string = row[\"characters\"]\n",
    "    \n",
    "    characters = json.loads(string)\n",
    "    if characters[\"items\"]:\n",
    "        for character in characters[\"items\"]:\n",
    "            with driver.session() as session:\n",
    "                try:\n",
    "                    character_id = character[\"resourceURI\"].split(\"/\")\n",
    "                    character_id = character_id[len(character_id) -1]\n",
    "                    session.write_transaction(\n",
    "                            add_comic_node_and_link, row['title'], row[\"id\"], character_id,  row[\"description\"])\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    else:\n",
    "        with driver.session() as session:\n",
    "            try:\n",
    "                session.write_transaction(\n",
    "                    add_comic_node, row['title'], row[\"id\"],  row[\"description\"])\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserimento personaggi da web scraping\n",
    "\n",
    "Se un personaggio base è già presente, quindi era presente nella lista personaggi ottenuta dalla web api, viene creata o aggiornata la variante del personaggio, se invece non è presente viene creato un personaggio base e la corrispondente variante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_present(tx, character):\n",
    "  res = tx.run(\"Match (n:character) where n.name='%s' return n\"%(character))\n",
    "  if res.single():\n",
    "    return True\n",
    "  else:\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_character_node(tx, name ):\n",
    "    create_comic_node_query = 'MERGE (c:character {name:\"%s\", wiki: true })' %(name)\n",
    "    tx.run(create_comic_node_query)\n",
    "\n",
    "def add_variant_node(tx, name, variant_name, biography):\n",
    "    tx.run('MERGE (b:character_variant {name: \"%s\"}) SET b.biography = \"%s\", b.wiki = true'%(variant_name, str(biography).replace(\"'\",\"\\\\'\").replace('\"','\\\\\"').replace(\"-\",\"\\\\-\").strip()))\n",
    "    query_variant = 'MATCH (a:character{name:\"%s\"}),(b:character_variant {name: \"%s\", wiki: true}) MERGE (b)-[r:variante_di]->(a)' % (\n",
    "       name, variant_name)\n",
    "    tx.run(query_variant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\",password))\n",
    "num_present = 0\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        character_data = pd.read_csv(\n",
    "            \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "        for idx, row in tqdm(character_data.iterrows(), total=character_data.shape[0]):\n",
    "            name = row[\"Nome\"]\n",
    "            name = name.replace('\"', \" \").replace(\"'\", \" \")\n",
    "            nome_senza_parentesi = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", name.strip())\n",
    "            nome_senza_parentesi = nome_senza_parentesi.strip().lower()\n",
    "            present = session.write_transaction(\n",
    "                character_present, nome_senza_parentesi)\n",
    "            if present:\n",
    "                num_present +=1\n",
    "                session.write_transaction(add_variant_node, nome_senza_parentesi, name, row[\"Biografia\"])\n",
    "            else:\n",
    "                session.write_transaction(add_character_node, nome_senza_parentesi)\n",
    "                session.write_transaction(\n",
    "                    add_variant_node, nome_senza_parentesi, name, row[\"Biografia\"])\n",
    "    except Exception as e:\n",
    "        print(e\n",
    "        )\n",
    "print(num_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3746/3746 [02:44<00:00, 22.82it/s]\n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "num_present = 0\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        character_data = pd.read_csv(\n",
    "            \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "        for idx, row in tqdm(character_data.iterrows(), total=character_data.shape[0]):\n",
    "          name = row[\"Nome\"]\n",
    "          name = name.replace('\"', \" \").replace(\"'\", \" \")\n",
    "          session.run(\"MATCH (n:character_variant) WHERE n.name = '%s' SET n.biography = '%s'\" % (\n",
    "              name, row[\"Processed_Biography\"]))\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserimento dati film\n",
    "Inserimento dei dati nel database, i personaggi che hanno film nei dati dei personaggi sono collegati ai rispettivi nodi film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charachter_name must have \" and ' replaced with whytespace and should be trimmed\n",
    "#movie_title must have \" and ' replaced with whytespace and should be trimmed\n",
    "def add_movie_node_and_link_character(tx, movie_title, character_name):\n",
    "  #create relation between movie anc character if mot exists\n",
    "  tx.run(\"MATCH (m:movie), (c:character_variant) WHERE m.title = '%s' AND c.name = '%s' MERGE (c)-[r:in_film]->(m)\"%(movie_title, character_name))\n",
    "\n",
    "#movie_title must have \" and ' and - replaced with whytespace and should be trimmed\n",
    "def add_movie(tx, movie_title, release_date, runtime, box_office, synopsis):\n",
    "  #create movie node if not exists\n",
    "  tx.run(\"MERGE (n:movie {title: '%s', release_date: '%s', screen_time: '%s', box_office: '%s', synopsis: '%s' })\" % (movie_title, release_date, runtime, box_office, synopsis))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:04<00:00, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "num_present = 0\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        film_data = pd.read_csv(\n",
    "            \"./Datasets/film_data_scraping.csv\")\n",
    "        for idx, row in tqdm(film_data.iterrows(), total=film_data.shape[0]):\n",
    "          \n",
    "            film_title = row[\"Title\"].strip() if str(row[\"Title\"]) != \"nan\" else None\n",
    "            film_release_date = row[\"releaseDate\"].strip(\n",
    "            ) if str(row[\"releaseDate\"]) != \"nan\" else None\n",
    "            film_runtime = row[\"Runtime\"].strip() if str(\n",
    "                row[\"Runtime\"]) != \"nan\" else None\n",
    "            film_box_office = row[\"BoxOffice\"].strip(\n",
    "            ) if str(row[\"BoxOffice\"]) != \"nan\" else None\n",
    "            film_synopsis = json.loads(row[\"Synopsis\"])[\n",
    "                0] if str(row[\"Synopsis\"]) != \"nan\" else None\n",
    "            #remove illegal string characters\n",
    "            if film_title:\n",
    "                film_title = film_title.replace('\"', \" \").replace(\"'\", \" \").replace(\"-\",\" \").strip()\n",
    "            #remove useless characters from synopsis\n",
    "            if film_synopsis:\n",
    "                film_synopsis = film_synopsis.replace(\"-\",\"\\-\").replace(\"'\",\"\\\\'\").replace('\"','\\\\\"').strip()\n",
    "            session.write_transaction(\n",
    "                    add_movie, film_title, film_release_date, film_runtime, film_box_office, film_synopsis)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione relazioni fra personaggi e film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3746/3746 [00:56<00:00, 66.25it/s] \n"
     ]
    }
   ],
   "source": [
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "num_present = 0\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        character_data = pd.read_csv(\n",
    "            \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "        for idx, row in tqdm(character_data.iterrows(), total=character_data.shape[0]):\n",
    "            films = json.loads(row[\"Film\"])\n",
    "            name = row[\"Nome\"]\n",
    "            name = name.replace('\"', \" \").replace(\"'\", \" \")\n",
    "            for film in films:\n",
    "                film_name = film[0]\n",
    "                film_name = film_name.replace('\"', \" \").replace(\n",
    "                    \"'\", \" \").replace(\"-\", \" \").strip()\n",
    "                session.write_transaction(add_movie_node_and_link_character, film_name, name)           \n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiunta delle serie nel database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione per ogni serie di un nodo di tipo *serie* contenente le varie info ottenute e collegamento ai nodi *character variant* corrispondenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definizione delle funzioni\n",
    "Definizione delle funzioni utilizzate per l'inserimento nel database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def escape_for_neo4j(string):\n",
    "  return string.replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\").replace(\"-\", \"\\\\-\").strip()\n",
    "def create_node_tv_serie(tx, title, creators, showrunners, producers, composers, release_date):\n",
    "  creators_list = list(map(lambda item: re.escape(item[0]).replace(\"\\ \",\" \").strip(), creators))\n",
    "  showrunners_list = list(\n",
    "      map(lambda item: escape_for_neo4j(item[0]).strip(), showrunners))\n",
    "  producers_list = list(\n",
    "      map(lambda item: escape_for_neo4j(item[0]).strip(), producers))\n",
    "  composers_list = list(\n",
    "      map(lambda item: escape_for_neo4j(item[0]).strip(), composers))\n",
    "  #remove illegal characters \n",
    "  title = escape_for_neo4j(title)\n",
    "  release_date = escape_for_neo4j(release_date)\n",
    "  #prepare query\n",
    "  query_string = \"MERGE (n:tv_show {title:'%s', creators:%s, showrunners: %s, producers: %s, composers: %s, release_date: '%s'})\"%(title, creators_list, showrunners_list, producers_list,composers_list, release_date)\n",
    "  tx.run(query_string)\n",
    "#name = name.replace('\"', \" \").replace(\"'\", \" \")\n",
    "def link_character_and_series(tx, character_name, serie_name):\n",
    "  character_name = character_name.replace('\"', \" \").replace(\"'\", \" \")\n",
    "  serie_name = escape_for_neo4j(serie_name)\n",
    "  query_string = \"MATCH (c:character_variant), (s:tv_show) WHERE c.name = '%s' AND s.title = '%s' MERGE (c)-[r:in_serie]->(s)\"%(character_name, serie_name)\n",
    "  tx.run(query_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add series nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:02<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "tv_series_dataframe = pd.read_csv(\"./Datasets/tv_series.csv\")\n",
    "\n",
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "with driver.session() as session:\n",
    "  try:\n",
    "    for idx, row in tqdm(tv_series_dataframe.iterrows(), total=tv_series_dataframe.shape[0]):\n",
    "      try:\n",
    "        title = row[\"Title\"]\n",
    "        creators = json.loads(row[\"Creators\"])\n",
    "        Showrunners = json.loads(row[\"Showrunners\"])\n",
    "        Producers = json.loads(row[\"Producers\"])\n",
    "        Composers = json.loads(row[\"Composers\"])\n",
    "        release_date = row[\"releaseDate\"]\n",
    "        session.write_transaction(create_node_tv_serie,title, creators, Showrunners, Producers, Composers, str(release_date))\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "  except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link characters with series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_dataframe = pd.read_csv(\n",
    "    \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "\n",
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "error_log = []\n",
    "with driver.session() as session:\n",
    "  try:\n",
    "    for idx, row in tqdm(characters_dataframe.iterrows(), total=characters_dataframe.shape[0]):\n",
    "      try:\n",
    "        series = json.loads(row[\"Serie\"])\n",
    "        character_name = row[\"Nome\"]\n",
    "        series = list(map(lambda item: escape_for_neo4j(item[0]), series))\n",
    "        for item in series:\n",
    "          session.write_transaction(link_character_and_series, character_name, item)\n",
    "      except Exception as e:\n",
    "        error_log.append(e)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "print(error_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link characters using relations found on wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relation(tx, first_character, second_character, relation_type):\n",
    "  query_string = \"MATCH (c:character_variant),(o:character_variant) WHERE c.name = '%s' AND o.name = '%s' MERGE (c)-[r:knows {type: '%s'}]->(o)\"%(first_character, second_character, relation_type)\n",
    "  tx.run(query_string)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3746/3746 [00:11<00:00, 322.25it/s]\n"
     ]
    }
   ],
   "source": [
    "characters_dataframe = pd.read_csv(\n",
    "    \"./Datasets/scraping_personaggi_completo_filtered_relations.csv\")\n",
    "characters_dataframe.head(20)\n",
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "import numpy as np\n",
    "#†\n",
    "with driver.session() as session:\n",
    "    try:\n",
    "        for idx, row in tqdm(characters_dataframe.iterrows(), total=characters_dataframe.shape[0]):\n",
    "            relazioni = json.loads(row[\"Filtered_relazioni\"] if str(row[\"Filtered_relazioni\"]) != \"nan\" else \"[]\")\n",
    "            for relation in relazioni:\n",
    "                \n",
    "                name = relation[0].replace(\"†\", \"\").replace(\n",
    "                    '\"', \" \").replace(\"'\", \" \").strip()\n",
    "                splitted = name.split(\"/\")\n",
    "                for splitted_relation in splitted:\n",
    "                    first_name = row[\"Nome\"].replace(\"†\", \"\").replace(\n",
    "                        '\"', \" \").replace(\"'\", \" \").strip()\n",
    "                    rel_type = relation[1] if len(relation) == 2 else \"\" \n",
    "                    session.write_transaction(\n",
    "                        create_relation, first_name, splitted_relation, rel_type)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tx):\n",
    "  res =  tx.run(\"match (n:character_variant {wiki: true}) return n limit 1000\")\n",
    "  for result in res:\n",
    "    print(result)\n",
    "driver = GraphDatabase.driver(db_host, auth=(\"neo4j\", password))\n",
    "with driver.session() as session:\n",
    "  session.write_transaction(test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
